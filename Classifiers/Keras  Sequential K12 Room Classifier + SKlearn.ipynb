{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "several-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "path='C:\\\\Users\\dmckenzie\\Desktop\\K12RoomTypeClassData2.csv'\n",
    "DATIS=pd.read_csv(path)\n",
    "DATIS=DATIS.drop(columns='Unnamed: 0')\n",
    "import re\n",
    "def preprocessor(text): \n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "DATIS['CleanName']=DATIS['RoomName'].str.replace('/',' ').replace({' +':' '},regex=True).apply(preprocessor)\n",
    "DATIS['NameLen']=DATIS['RoomName'].str.len()\n",
    "DATIS['RoomName']=DATIS['RoomName'].str.lower()\n",
    "DATIS['TokenCount']=((DATIS['RoomName'].str.len()-DATIS['RoomName'].str.replace(' ','').str.len())+1)\n",
    "DATIS.Label2=DATIS.Label2.str.lower()\n",
    "DATIS['RoomType']=np.where(DATIS['RoomName'].str.lower().str.contains('corridor'),'corridor',\n",
    "         np.where(DATIS['RoomName'].str.lower().str.contains('shower'),'shower',\n",
    "         np.where(DATIS['RoomName'].str.contains('|'.join([' rr','restroom','bathroom','lavartory',\n",
    "                                                        'washroom','wash room','wash_room',\n",
    "                                                        'tlt','toielt','bath room','rest room',\n",
    "                                                        'bath_room','rest_room'])),'bathroom',\n",
    "           np.where(DATIS['Label2']=='small group','other',        \n",
    "          np.where(DATIS['Label2']=='special english','other',DATIS['Label2'])))))\n",
    "\n",
    "binomiallist=[]\n",
    "for i in range(0,len(DATIS)):\n",
    "        binomiallist.append(np.random.binomial(1, .025))\n",
    "\n",
    "DATIS['Keep']=binomiallist\n",
    "DATIS['Keep']=np.where(DATIS['RoomType']=='other',DATIS['Keep'],1)\n",
    "DATIS2=DATIS[DATIS['Keep']==1]\n",
    "DATIS2=DATIS2.drop_duplicates(['RoomType','CleanName'])\n",
    "y = DATIS2.RoomType.str.lower()\n",
    "DATIS2['Name'] = DATIS2['CleanName']\n",
    "X = DATIS2['Name']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grateful-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69bfe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec=CountVectorizer()\n",
    "vec.fit(X_train)   \n",
    "#=vec.fit(X_train)\n",
    "#X.toarray()\n",
    "skX=vec.transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4344c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X_train))\n",
    "train_tags = y_train\n",
    "test_tags = y_test\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "num_classes = 23\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "54587332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "11e1ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized=text_vectorizer(list(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4fb54e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized2=text_vectorizer(list(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6a1ea",
   "metadata": {},
   "source": [
    "if not os.path.exists(\"simple_GRU\"):\n",
    "    os.mkdir(\"simple_GRU\")\n",
    "tf.keras.models.save_model(model, \"simple_GUR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "999c602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "7/7 [==============================] - 5s 563ms/step - loss: 3.1053 - accuracy: 0.1078 - val_loss: 3.0165 - val_accuracy: 0.1831\n",
      "Epoch 2/250\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 2.9716 - accuracy: 0.1775 - val_loss: 2.8565 - val_accuracy: 0.1831\n",
      "Epoch 3/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 2.8229 - accuracy: 0.1775 - val_loss: 2.7149 - val_accuracy: 0.1831\n",
      "Epoch 4/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 2.7325 - accuracy: 0.1775 - val_loss: 2.6682 - val_accuracy: 0.1831\n",
      "Epoch 5/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 2.7070 - accuracy: 0.1775 - val_loss: 2.6629 - val_accuracy: 0.1831\n",
      "Epoch 6/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 2.7025 - accuracy: 0.1775 - val_loss: 2.6782 - val_accuracy: 0.1831\n",
      "Epoch 7/250\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 2.6946 - accuracy: 0.1775 - val_loss: 2.6691 - val_accuracy: 0.1831\n",
      "Epoch 8/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 2.6887 - accuracy: 0.1775 - val_loss: 2.6612 - val_accuracy: 0.1831\n",
      "Epoch 9/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 2.6888 - accuracy: 0.1775 - val_loss: 2.6609 - val_accuracy: 0.1831\n",
      "Epoch 10/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 2.6898 - accuracy: 0.1775 - val_loss: 2.6688 - val_accuracy: 0.1831\n",
      "Epoch 11/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 2.6880 - accuracy: 0.1775 - val_loss: 2.6781 - val_accuracy: 0.1831\n",
      "Epoch 12/250\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 2.6887 - accuracy: 0.1775 - val_loss: 2.6815 - val_accuracy: 0.1831\n",
      "Epoch 13/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 2.6870 - accuracy: 0.1775 - val_loss: 2.6818 - val_accuracy: 0.1831\n",
      "Epoch 14/250\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 2.6854 - accuracy: 0.1791 - val_loss: 2.6828 - val_accuracy: 0.1831\n",
      "Epoch 15/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 2.6863 - accuracy: 0.1791 - val_loss: 2.6778 - val_accuracy: 0.1831\n",
      "Epoch 16/250\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 2.6851 - accuracy: 0.1791 - val_loss: 2.6722 - val_accuracy: 0.1831\n",
      "Epoch 17/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 2.6858 - accuracy: 0.1791 - val_loss: 2.6708 - val_accuracy: 0.1831\n",
      "Epoch 18/250\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 2.6833 - accuracy: 0.1791 - val_loss: 2.6739 - val_accuracy: 0.1831\n",
      "Epoch 19/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 2.6838 - accuracy: 0.1791 - val_loss: 2.6792 - val_accuracy: 0.1831\n",
      "Epoch 20/250\n",
      "7/7 [==============================] - 4s 520ms/step - loss: 2.6808 - accuracy: 0.1791 - val_loss: 2.6830 - val_accuracy: 0.1831\n",
      "Epoch 21/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.6775 - accuracy: 0.1854 - val_loss: 2.6785 - val_accuracy: 0.1831\n",
      "Epoch 22/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 2.6725 - accuracy: 0.1870 - val_loss: 2.6644 - val_accuracy: 0.1831\n",
      "Epoch 23/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 2.6633 - accuracy: 0.1965 - val_loss: 2.6649 - val_accuracy: 0.1831\n",
      "Epoch 24/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 2.6514 - accuracy: 0.1981 - val_loss: 2.6618 - val_accuracy: 0.1831\n",
      "Epoch 25/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 2.6357 - accuracy: 0.2044 - val_loss: 2.6496 - val_accuracy: 0.2394\n",
      "Epoch 26/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 2.6198 - accuracy: 0.2124 - val_loss: 2.6425 - val_accuracy: 0.1831\n",
      "Epoch 27/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 2.5996 - accuracy: 0.2631 - val_loss: 2.6266 - val_accuracy: 0.2676\n",
      "Epoch 28/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 2.5820 - accuracy: 0.2726 - val_loss: 2.6148 - val_accuracy: 0.2676\n",
      "Epoch 29/250\n",
      "7/7 [==============================] - 4s 532ms/step - loss: 2.5616 - accuracy: 0.2694 - val_loss: 2.5966 - val_accuracy: 0.2676\n",
      "Epoch 30/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 2.5377 - accuracy: 0.2694 - val_loss: 2.5859 - val_accuracy: 0.2535\n",
      "Epoch 31/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 2.5173 - accuracy: 0.2726 - val_loss: 2.5792 - val_accuracy: 0.2676\n",
      "Epoch 32/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 2.4959 - accuracy: 0.2726 - val_loss: 2.5722 - val_accuracy: 0.2535\n",
      "Epoch 33/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 2.4797 - accuracy: 0.2773 - val_loss: 2.5624 - val_accuracy: 0.3521\n",
      "Epoch 34/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 2.4641 - accuracy: 0.2932 - val_loss: 2.5628 - val_accuracy: 0.3239\n",
      "Epoch 35/250\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 2.4466 - accuracy: 0.2758 - val_loss: 2.6023 - val_accuracy: 0.2535\n",
      "Epoch 36/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.4493 - accuracy: 0.2678 - val_loss: 2.5697 - val_accuracy: 0.2535\n",
      "Epoch 37/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 2.4255 - accuracy: 0.2932 - val_loss: 2.5660 - val_accuracy: 0.2676\n",
      "Epoch 38/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 2.4135 - accuracy: 0.2995 - val_loss: 2.5437 - val_accuracy: 0.3521\n",
      "Epoch 39/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 2.3946 - accuracy: 0.3185 - val_loss: 2.5502 - val_accuracy: 0.3099\n",
      "Epoch 40/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 2.3799 - accuracy: 0.3011 - val_loss: 2.5647 - val_accuracy: 0.2958\n",
      "Epoch 41/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.3666 - accuracy: 0.2916 - val_loss: 2.5585 - val_accuracy: 0.3380\n",
      "Epoch 42/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 2.3505 - accuracy: 0.3281 - val_loss: 2.5570 - val_accuracy: 0.2817\n",
      "Epoch 43/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 2.3379 - accuracy: 0.3249 - val_loss: 2.5647 - val_accuracy: 0.2676\n",
      "Epoch 44/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 2.3314 - accuracy: 0.3043 - val_loss: 2.5695 - val_accuracy: 0.2958\n",
      "Epoch 45/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 2.3254 - accuracy: 0.3043 - val_loss: 2.5561 - val_accuracy: 0.2817\n",
      "Epoch 46/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 2.3064 - accuracy: 0.3090 - val_loss: 2.5771 - val_accuracy: 0.2535\n",
      "Epoch 47/250\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 2.3018 - accuracy: 0.3059 - val_loss: 2.5613 - val_accuracy: 0.3239\n",
      "Epoch 48/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.2914 - accuracy: 0.3043 - val_loss: 2.5517 - val_accuracy: 0.2535\n",
      "Epoch 49/250\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 2.2737 - accuracy: 0.3217 - val_loss: 2.5387 - val_accuracy: 0.2958\n",
      "Epoch 50/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.2650 - accuracy: 0.3106 - val_loss: 2.5411 - val_accuracy: 0.2958\n",
      "Epoch 51/250\n",
      "7/7 [==============================] - 4s 520ms/step - loss: 2.2653 - accuracy: 0.3090 - val_loss: 2.5296 - val_accuracy: 0.2958\n",
      "Epoch 52/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 2.2478 - accuracy: 0.3423 - val_loss: 2.5373 - val_accuracy: 0.2676\n",
      "Epoch 53/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 2.2447 - accuracy: 0.3344 - val_loss: 2.5244 - val_accuracy: 0.3099\n",
      "Epoch 54/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.2297 - accuracy: 0.3170 - val_loss: 2.5196 - val_accuracy: 0.3239\n",
      "Epoch 55/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 2.2192 - accuracy: 0.3471 - val_loss: 2.4964 - val_accuracy: 0.2958\n",
      "Epoch 56/250\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 2.2029 - accuracy: 0.3550 - val_loss: 2.4900 - val_accuracy: 0.3380\n",
      "Epoch 57/250\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 2.1991 - accuracy: 0.3645 - val_loss: 2.5034 - val_accuracy: 0.2676\n",
      "Epoch 58/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 2.1890 - accuracy: 0.3582 - val_loss: 2.4905 - val_accuracy: 0.3099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 2.1885 - accuracy: 0.3502 - val_loss: 2.4602 - val_accuracy: 0.3239\n",
      "Epoch 60/250\n",
      "7/7 [==============================] - 4s 525ms/step - loss: 2.1727 - accuracy: 0.3534 - val_loss: 2.4759 - val_accuracy: 0.3380\n",
      "Epoch 61/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 2.1710 - accuracy: 0.3613 - val_loss: 2.4757 - val_accuracy: 0.3380\n",
      "Epoch 62/250\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 2.1663 - accuracy: 0.3708 - val_loss: 2.4793 - val_accuracy: 0.3380\n",
      "Epoch 63/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.1534 - accuracy: 0.3487 - val_loss: 2.4849 - val_accuracy: 0.3239\n",
      "Epoch 64/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 2.1518 - accuracy: 0.3724 - val_loss: 2.4645 - val_accuracy: 0.3239\n",
      "Epoch 65/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.1773 - accuracy: 0.3391 - val_loss: 2.4770 - val_accuracy: 0.2535\n",
      "Epoch 66/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 2.1332 - accuracy: 0.3629 - val_loss: 2.4381 - val_accuracy: 0.3521\n",
      "Epoch 67/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 2.1156 - accuracy: 0.3724 - val_loss: 2.4193 - val_accuracy: 0.3662\n",
      "Epoch 68/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 2.1033 - accuracy: 0.3819 - val_loss: 2.4122 - val_accuracy: 0.3521\n",
      "Epoch 69/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 2.0945 - accuracy: 0.3851 - val_loss: 2.3943 - val_accuracy: 0.3803\n",
      "Epoch 70/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 2.0778 - accuracy: 0.3962 - val_loss: 2.4015 - val_accuracy: 0.3521\n",
      "Epoch 71/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.0828 - accuracy: 0.3740 - val_loss: 2.4381 - val_accuracy: 0.3380\n",
      "Epoch 72/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 2.0701 - accuracy: 0.3772 - val_loss: 2.3677 - val_accuracy: 0.3521\n",
      "Epoch 73/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 2.0477 - accuracy: 0.3994 - val_loss: 2.3664 - val_accuracy: 0.3944\n",
      "Epoch 74/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 2.0551 - accuracy: 0.3962 - val_loss: 2.4120 - val_accuracy: 0.3521\n",
      "Epoch 75/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 2.0455 - accuracy: 0.3946 - val_loss: 2.3461 - val_accuracy: 0.3803\n",
      "Epoch 76/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 2.0236 - accuracy: 0.3851 - val_loss: 2.3387 - val_accuracy: 0.3803\n",
      "Epoch 77/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.0253 - accuracy: 0.4010 - val_loss: 2.3283 - val_accuracy: 0.3662\n",
      "Epoch 78/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 2.0273 - accuracy: 0.3835 - val_loss: 2.3306 - val_accuracy: 0.3803\n",
      "Epoch 79/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 2.0260 - accuracy: 0.3772 - val_loss: 2.3298 - val_accuracy: 0.3662\n",
      "Epoch 80/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.0254 - accuracy: 0.3788 - val_loss: 2.3484 - val_accuracy: 0.3662\n",
      "Epoch 81/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 2.0154 - accuracy: 0.3835 - val_loss: 2.3291 - val_accuracy: 0.4085\n",
      "Epoch 82/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 2.0118 - accuracy: 0.3819 - val_loss: 2.2853 - val_accuracy: 0.3662\n",
      "Epoch 83/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.9830 - accuracy: 0.3930 - val_loss: 2.3171 - val_accuracy: 0.3944\n",
      "Epoch 84/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 1.9761 - accuracy: 0.3962 - val_loss: 2.3024 - val_accuracy: 0.3662\n",
      "Epoch 85/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.9731 - accuracy: 0.4010 - val_loss: 2.3154 - val_accuracy: 0.4085\n",
      "Epoch 86/250\n",
      "7/7 [==============================] - 4s 502ms/step - loss: 1.9661 - accuracy: 0.4105 - val_loss: 2.2892 - val_accuracy: 0.3662\n",
      "Epoch 87/250\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 1.9696 - accuracy: 0.3978 - val_loss: 2.3341 - val_accuracy: 0.3662\n",
      "Epoch 88/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.9363 - accuracy: 0.4120 - val_loss: 2.2753 - val_accuracy: 0.3944\n",
      "Epoch 89/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.9420 - accuracy: 0.3994 - val_loss: 2.2909 - val_accuracy: 0.3803\n",
      "Epoch 90/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.9276 - accuracy: 0.4089 - val_loss: 2.2628 - val_accuracy: 0.4225\n",
      "Epoch 91/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 1.9177 - accuracy: 0.4279 - val_loss: 2.2322 - val_accuracy: 0.4225\n",
      "Epoch 92/250\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 1.9193 - accuracy: 0.4247 - val_loss: 2.2779 - val_accuracy: 0.3803\n",
      "Epoch 93/250\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 1.9211 - accuracy: 0.4247 - val_loss: 2.2840 - val_accuracy: 0.4225\n",
      "Epoch 94/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.9298 - accuracy: 0.4200 - val_loss: 2.2866 - val_accuracy: 0.3662\n",
      "Epoch 95/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.9078 - accuracy: 0.4057 - val_loss: 2.2813 - val_accuracy: 0.4085\n",
      "Epoch 96/250\n",
      "7/7 [==============================] - 4s 525ms/step - loss: 1.9013 - accuracy: 0.4120 - val_loss: 2.2891 - val_accuracy: 0.4366\n",
      "Epoch 97/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.9047 - accuracy: 0.4295 - val_loss: 2.2531 - val_accuracy: 0.3944\n",
      "Epoch 98/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.8771 - accuracy: 0.4247 - val_loss: 2.2302 - val_accuracy: 0.4085\n",
      "Epoch 99/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.8750 - accuracy: 0.4326 - val_loss: 2.2571 - val_accuracy: 0.4366\n",
      "Epoch 100/250\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 1.8621 - accuracy: 0.4216 - val_loss: 2.2389 - val_accuracy: 0.4366\n",
      "Epoch 101/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 1.8509 - accuracy: 0.4279 - val_loss: 2.2318 - val_accuracy: 0.4085\n",
      "Epoch 102/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.8671 - accuracy: 0.4342 - val_loss: 2.2821 - val_accuracy: 0.4225\n",
      "Epoch 103/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 1.8678 - accuracy: 0.4295 - val_loss: 2.2683 - val_accuracy: 0.4225\n",
      "Epoch 104/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 1.8661 - accuracy: 0.4216 - val_loss: 2.2291 - val_accuracy: 0.3944\n",
      "Epoch 105/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.8484 - accuracy: 0.4263 - val_loss: 2.2927 - val_accuracy: 0.3944\n",
      "Epoch 106/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.8650 - accuracy: 0.4263 - val_loss: 2.2890 - val_accuracy: 0.4225\n",
      "Epoch 107/250\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 1.9149 - accuracy: 0.4326 - val_loss: 2.3479 - val_accuracy: 0.3662\n",
      "Epoch 108/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.9156 - accuracy: 0.4073 - val_loss: 2.3354 - val_accuracy: 0.3944\n",
      "Epoch 109/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 1.8843 - accuracy: 0.4279 - val_loss: 2.3228 - val_accuracy: 0.4085\n",
      "Epoch 110/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.8665 - accuracy: 0.4326 - val_loss: 2.2754 - val_accuracy: 0.3803\n",
      "Epoch 111/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 1.8543 - accuracy: 0.4358 - val_loss: 2.2640 - val_accuracy: 0.4085\n",
      "Epoch 112/250\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 1.8381 - accuracy: 0.4295 - val_loss: 2.2127 - val_accuracy: 0.3803\n",
      "Epoch 113/250\n",
      "7/7 [==============================] - 4s 520ms/step - loss: 1.8100 - accuracy: 0.4501 - val_loss: 2.2363 - val_accuracy: 0.4225\n",
      "Epoch 114/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.8090 - accuracy: 0.4342 - val_loss: 2.2651 - val_accuracy: 0.4085\n",
      "Epoch 115/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.8460 - accuracy: 0.4200 - val_loss: 2.2791 - val_accuracy: 0.3803\n",
      "Epoch 116/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.8606 - accuracy: 0.4247 - val_loss: 2.2200 - val_accuracy: 0.4366\n",
      "Epoch 117/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 1.8442 - accuracy: 0.4311 - val_loss: 2.2382 - val_accuracy: 0.4366\n",
      "Epoch 118/250\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 1.8150 - accuracy: 0.4231 - val_loss: 2.2004 - val_accuracy: 0.4085\n",
      "Epoch 119/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 1.7972 - accuracy: 0.4485 - val_loss: 2.2167 - val_accuracy: 0.3944\n",
      "Epoch 120/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.7941 - accuracy: 0.4390 - val_loss: 2.1948 - val_accuracy: 0.4085\n",
      "Epoch 121/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.7867 - accuracy: 0.4311 - val_loss: 2.1916 - val_accuracy: 0.4085\n",
      "Epoch 122/250\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 1.7820 - accuracy: 0.4501 - val_loss: 2.1772 - val_accuracy: 0.3944\n",
      "Epoch 123/250\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 1.7767 - accuracy: 0.4628 - val_loss: 2.2200 - val_accuracy: 0.4225\n",
      "Epoch 124/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.7600 - accuracy: 0.4548 - val_loss: 2.1827 - val_accuracy: 0.3944\n",
      "Epoch 125/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 1.7837 - accuracy: 0.4564 - val_loss: 2.2043 - val_accuracy: 0.4085\n",
      "Epoch 126/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.7526 - accuracy: 0.4691 - val_loss: 2.2179 - val_accuracy: 0.4085\n",
      "Epoch 127/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.7658 - accuracy: 0.4596 - val_loss: 2.2214 - val_accuracy: 0.3662\n",
      "Epoch 128/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.7587 - accuracy: 0.4580 - val_loss: 2.1777 - val_accuracy: 0.4225\n",
      "Epoch 129/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 1.7488 - accuracy: 0.4548 - val_loss: 2.1683 - val_accuracy: 0.4225\n",
      "Epoch 130/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 1.7395 - accuracy: 0.4580 - val_loss: 2.1804 - val_accuracy: 0.4085\n",
      "Epoch 131/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.7287 - accuracy: 0.4675 - val_loss: 2.1883 - val_accuracy: 0.4366\n",
      "Epoch 132/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.7433 - accuracy: 0.4818 - val_loss: 2.2298 - val_accuracy: 0.4085\n",
      "Epoch 133/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.7831 - accuracy: 0.4469 - val_loss: 2.2246 - val_accuracy: 0.4085\n",
      "Epoch 134/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.7785 - accuracy: 0.4437 - val_loss: 2.2208 - val_accuracy: 0.3803\n",
      "Epoch 135/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.7552 - accuracy: 0.4596 - val_loss: 2.1930 - val_accuracy: 0.4085\n",
      "Epoch 136/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.7275 - accuracy: 0.4739 - val_loss: 2.1979 - val_accuracy: 0.3944\n",
      "Epoch 137/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 1.7407 - accuracy: 0.4501 - val_loss: 2.2087 - val_accuracy: 0.4085\n",
      "Epoch 138/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 1.7487 - accuracy: 0.4739 - val_loss: 2.2256 - val_accuracy: 0.3944\n",
      "Epoch 139/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 1.7203 - accuracy: 0.4802 - val_loss: 2.1971 - val_accuracy: 0.4085\n",
      "Epoch 140/250\n",
      "7/7 [==============================] - 4s 519ms/step - loss: 1.6989 - accuracy: 0.4691 - val_loss: 2.1871 - val_accuracy: 0.4085\n",
      "Epoch 141/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 1.7060 - accuracy: 0.4786 - val_loss: 2.2219 - val_accuracy: 0.4085\n",
      "Epoch 142/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.7358 - accuracy: 0.4675 - val_loss: 2.2028 - val_accuracy: 0.4366\n",
      "Epoch 143/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.6969 - accuracy: 0.4691 - val_loss: 2.1695 - val_accuracy: 0.4085\n",
      "Epoch 144/250\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 1.7139 - accuracy: 0.4913 - val_loss: 2.2409 - val_accuracy: 0.4085\n",
      "Epoch 145/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.7175 - accuracy: 0.4802 - val_loss: 2.2019 - val_accuracy: 0.4085\n",
      "Epoch 146/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.6967 - accuracy: 0.4770 - val_loss: 2.1708 - val_accuracy: 0.3944\n",
      "Epoch 147/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.6896 - accuracy: 0.4834 - val_loss: 2.1837 - val_accuracy: 0.4225\n",
      "Epoch 148/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.6756 - accuracy: 0.4881 - val_loss: 2.2038 - val_accuracy: 0.4225\n",
      "Epoch 149/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.6728 - accuracy: 0.4960 - val_loss: 2.1981 - val_accuracy: 0.4225\n",
      "Epoch 150/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.6761 - accuracy: 0.4945 - val_loss: 2.1372 - val_accuracy: 0.4225\n",
      "Epoch 151/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.6748 - accuracy: 0.4976 - val_loss: 2.1682 - val_accuracy: 0.3944\n",
      "Epoch 152/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 1.7049 - accuracy: 0.4628 - val_loss: 2.2151 - val_accuracy: 0.3803\n",
      "Epoch 153/250\n",
      "7/7 [==============================] - 4s 520ms/step - loss: 1.7534 - accuracy: 0.4659 - val_loss: 2.2682 - val_accuracy: 0.4085\n",
      "Epoch 154/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.7203 - accuracy: 0.4739 - val_loss: 2.1861 - val_accuracy: 0.4085\n",
      "Epoch 155/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 1.7218 - accuracy: 0.4691 - val_loss: 2.1874 - val_accuracy: 0.3662\n",
      "Epoch 156/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.6988 - accuracy: 0.4659 - val_loss: 2.1655 - val_accuracy: 0.4225\n",
      "Epoch 157/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.6802 - accuracy: 0.4770 - val_loss: 2.1324 - val_accuracy: 0.4225\n",
      "Epoch 158/250\n",
      "7/7 [==============================] - 4s 520ms/step - loss: 1.6680 - accuracy: 0.4834 - val_loss: 2.1409 - val_accuracy: 0.4225\n",
      "Epoch 159/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 1.6594 - accuracy: 0.4992 - val_loss: 2.1911 - val_accuracy: 0.4366\n",
      "Epoch 160/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.6480 - accuracy: 0.5024 - val_loss: 2.1516 - val_accuracy: 0.4225\n",
      "Epoch 161/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.6407 - accuracy: 0.5071 - val_loss: 2.1678 - val_accuracy: 0.4366\n",
      "Epoch 162/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.6575 - accuracy: 0.4913 - val_loss: 2.1758 - val_accuracy: 0.4507\n",
      "Epoch 163/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.6541 - accuracy: 0.4849 - val_loss: 2.1893 - val_accuracy: 0.3944\n",
      "Epoch 164/250\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 1.6676 - accuracy: 0.4929 - val_loss: 2.1745 - val_accuracy: 0.4225\n",
      "Epoch 165/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 1.6497 - accuracy: 0.4913 - val_loss: 2.1503 - val_accuracy: 0.4085\n",
      "Epoch 166/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.6425 - accuracy: 0.5008 - val_loss: 2.1412 - val_accuracy: 0.4085\n",
      "Epoch 167/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.6397 - accuracy: 0.4897 - val_loss: 2.1217 - val_accuracy: 0.4366\n",
      "Epoch 168/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.6348 - accuracy: 0.4897 - val_loss: 2.0839 - val_accuracy: 0.4366\n",
      "Epoch 169/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.6093 - accuracy: 0.5071 - val_loss: 2.1129 - val_accuracy: 0.4366\n",
      "Epoch 170/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 1.6251 - accuracy: 0.5040 - val_loss: 2.1378 - val_accuracy: 0.4366\n",
      "Epoch 171/250\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 1.6174 - accuracy: 0.5040 - val_loss: 2.1366 - val_accuracy: 0.4366\n",
      "Epoch 172/250\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 1.6086 - accuracy: 0.5024 - val_loss: 2.0950 - val_accuracy: 0.4366\n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 4s 508ms/step - loss: 1.6186 - accuracy: 0.5008 - val_loss: 2.1472 - val_accuracy: 0.4648\n",
      "Epoch 174/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.6053 - accuracy: 0.5103 - val_loss: 2.1121 - val_accuracy: 0.4789\n",
      "Epoch 175/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.6041 - accuracy: 0.4976 - val_loss: 2.0822 - val_accuracy: 0.4648\n",
      "Epoch 176/250\n",
      "7/7 [==============================] - 4s 503ms/step - loss: 1.6051 - accuracy: 0.5119 - val_loss: 2.0994 - val_accuracy: 0.4648\n",
      "Epoch 177/250\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 1.6146 - accuracy: 0.4992 - val_loss: 2.1086 - val_accuracy: 0.4507\n",
      "Epoch 178/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.5955 - accuracy: 0.5071 - val_loss: 2.1349 - val_accuracy: 0.4507\n",
      "Epoch 179/250\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 1.6028 - accuracy: 0.5119 - val_loss: 2.1425 - val_accuracy: 0.4366\n",
      "Epoch 180/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 1.5986 - accuracy: 0.4897 - val_loss: 2.1093 - val_accuracy: 0.4085\n",
      "Epoch 181/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.6128 - accuracy: 0.4976 - val_loss: 2.0937 - val_accuracy: 0.4789\n",
      "Epoch 182/250\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 1.6030 - accuracy: 0.5024 - val_loss: 2.1300 - val_accuracy: 0.4225\n",
      "Epoch 183/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.5842 - accuracy: 0.5087 - val_loss: 2.1226 - val_accuracy: 0.4225\n",
      "Epoch 184/250\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 1.5894 - accuracy: 0.5151 - val_loss: 2.0881 - val_accuracy: 0.4507\n",
      "Epoch 185/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.5796 - accuracy: 0.5151 - val_loss: 2.1111 - val_accuracy: 0.4225\n",
      "Epoch 186/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.5813 - accuracy: 0.5182 - val_loss: 2.1547 - val_accuracy: 0.4085\n",
      "Epoch 187/250\n",
      "7/7 [==============================] - 4s 504ms/step - loss: 1.5698 - accuracy: 0.5182 - val_loss: 2.1408 - val_accuracy: 0.4225\n",
      "Epoch 188/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.5782 - accuracy: 0.5103 - val_loss: 2.0806 - val_accuracy: 0.4366\n",
      "Epoch 189/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 1.5776 - accuracy: 0.5071 - val_loss: 2.1426 - val_accuracy: 0.4366\n",
      "Epoch 190/250\n",
      "7/7 [==============================] - 4s 505ms/step - loss: 1.5730 - accuracy: 0.5071 - val_loss: 2.1783 - val_accuracy: 0.4366\n",
      "Epoch 191/250\n",
      "7/7 [==============================] - 4s 507ms/step - loss: 1.6178 - accuracy: 0.4945 - val_loss: 2.1180 - val_accuracy: 0.4507\n",
      "Epoch 192/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.6065 - accuracy: 0.5040 - val_loss: 2.1175 - val_accuracy: 0.4507\n",
      "Epoch 193/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.5711 - accuracy: 0.5119 - val_loss: 2.1496 - val_accuracy: 0.4930\n",
      "Epoch 194/250\n",
      "7/7 [==============================] - 4s 501ms/step - loss: 1.5782 - accuracy: 0.5040 - val_loss: 2.1248 - val_accuracy: 0.4507\n",
      "Epoch 195/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 1.6097 - accuracy: 0.4834 - val_loss: 2.1884 - val_accuracy: 0.4366\n",
      "Epoch 196/250\n",
      "7/7 [==============================] - 4s 506ms/step - loss: 1.6810 - accuracy: 0.4723 - val_loss: 2.1964 - val_accuracy: 0.4225\n",
      "Epoch 197/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 1.6407 - accuracy: 0.4881 - val_loss: 2.1039 - val_accuracy: 0.4085\n",
      "Epoch 198/250\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 1.5548 - accuracy: 0.5182 - val_loss: 2.1276 - val_accuracy: 0.4225\n",
      "Epoch 199/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.5622 - accuracy: 0.5055 - val_loss: 2.0627 - val_accuracy: 0.4648\n",
      "Epoch 200/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 1.5420 - accuracy: 0.5103 - val_loss: 2.1017 - val_accuracy: 0.4789\n",
      "Epoch 201/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 1.5485 - accuracy: 0.5040 - val_loss: 2.0694 - val_accuracy: 0.4225\n",
      "Epoch 202/250\n",
      "7/7 [==============================] - 4s 523ms/step - loss: 1.5555 - accuracy: 0.5055 - val_loss: 2.1112 - val_accuracy: 0.4789\n",
      "Epoch 203/250\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 1.5390 - accuracy: 0.5151 - val_loss: 2.0799 - val_accuracy: 0.4648\n",
      "Epoch 204/250\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 1.5267 - accuracy: 0.5182 - val_loss: 2.0651 - val_accuracy: 0.4648\n",
      "Epoch 205/250\n",
      "7/7 [==============================] - 4s 515ms/step - loss: 1.5222 - accuracy: 0.5214 - val_loss: 2.0879 - val_accuracy: 0.4507\n",
      "Epoch 206/250\n",
      "7/7 [==============================] - 4s 517ms/step - loss: 1.5277 - accuracy: 0.5277 - val_loss: 2.0524 - val_accuracy: 0.4366\n",
      "Epoch 207/250\n",
      "7/7 [==============================] - 4s 524ms/step - loss: 1.5184 - accuracy: 0.5182 - val_loss: 2.0842 - val_accuracy: 0.4789\n",
      "Epoch 208/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.5249 - accuracy: 0.5119 - val_loss: 2.0296 - val_accuracy: 0.4507\n",
      "Epoch 209/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 1.5453 - accuracy: 0.5103 - val_loss: 2.0874 - val_accuracy: 0.4648\n",
      "Epoch 210/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.5350 - accuracy: 0.5214 - val_loss: 2.1435 - val_accuracy: 0.4789\n",
      "Epoch 211/250\n",
      "7/7 [==============================] - 4s 518ms/step - loss: 1.5492 - accuracy: 0.5040 - val_loss: 2.0845 - val_accuracy: 0.4507\n",
      "Epoch 212/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.5208 - accuracy: 0.5341 - val_loss: 2.0671 - val_accuracy: 0.4366\n",
      "Epoch 213/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 1.5164 - accuracy: 0.5214 - val_loss: 2.0656 - val_accuracy: 0.4648\n",
      "Epoch 214/250\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 1.5216 - accuracy: 0.5166 - val_loss: 2.1004 - val_accuracy: 0.4648\n",
      "Epoch 215/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.5245 - accuracy: 0.5198 - val_loss: 2.0598 - val_accuracy: 0.4648\n",
      "Epoch 216/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 1.5060 - accuracy: 0.5198 - val_loss: 2.0664 - val_accuracy: 0.4507\n",
      "Epoch 217/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.5208 - accuracy: 0.5277 - val_loss: 2.0156 - val_accuracy: 0.4507\n",
      "Epoch 218/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.5254 - accuracy: 0.5182 - val_loss: 2.0738 - val_accuracy: 0.4366\n",
      "Epoch 219/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.5092 - accuracy: 0.5261 - val_loss: 2.0514 - val_accuracy: 0.4507\n",
      "Epoch 220/250\n",
      "7/7 [==============================] - 4s 522ms/step - loss: 1.4961 - accuracy: 0.5372 - val_loss: 1.9900 - val_accuracy: 0.4789\n",
      "Epoch 221/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.5152 - accuracy: 0.5135 - val_loss: 2.0324 - val_accuracy: 0.4789\n",
      "Epoch 222/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.4967 - accuracy: 0.5277 - val_loss: 2.0311 - val_accuracy: 0.4930\n",
      "Epoch 223/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.4883 - accuracy: 0.5261 - val_loss: 2.0196 - val_accuracy: 0.4648\n",
      "Epoch 224/250\n",
      "7/7 [==============================] - 4s 521ms/step - loss: 1.4832 - accuracy: 0.5293 - val_loss: 2.0527 - val_accuracy: 0.4225\n",
      "Epoch 225/250\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 1.5056 - accuracy: 0.5309 - val_loss: 2.0815 - val_accuracy: 0.4789\n",
      "Epoch 226/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.5336 - accuracy: 0.5119 - val_loss: 2.5387 - val_accuracy: 0.2676\n",
      "Epoch 227/250\n",
      "7/7 [==============================] - 4s 510ms/step - loss: 2.6530 - accuracy: 0.2647 - val_loss: 3.1551 - val_accuracy: 0.1972\n",
      "Epoch 228/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 2.5189 - accuracy: 0.2789 - val_loss: 2.8061 - val_accuracy: 0.2817\n",
      "Epoch 229/250\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 2.2691 - accuracy: 0.3407 - val_loss: 2.5709 - val_accuracy: 0.2535\n",
      "Epoch 230/250\n",
      "7/7 [==============================] - 4s 508ms/step - loss: 2.1123 - accuracy: 0.3740 - val_loss: 2.4446 - val_accuracy: 0.3380\n",
      "Epoch 231/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 2.0444 - accuracy: 0.4216 - val_loss: 2.3454 - val_accuracy: 0.3944\n",
      "Epoch 232/250\n",
      "7/7 [==============================] - 4s 509ms/step - loss: 1.9917 - accuracy: 0.4295 - val_loss: 2.3000 - val_accuracy: 0.3944\n",
      "Epoch 233/250\n",
      "7/7 [==============================] - 4s 541ms/step - loss: 1.9438 - accuracy: 0.4311 - val_loss: 2.2735 - val_accuracy: 0.3803\n",
      "Epoch 234/250\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 1.9078 - accuracy: 0.4263 - val_loss: 2.2262 - val_accuracy: 0.3662\n",
      "Epoch 235/250\n",
      "7/7 [==============================] - 4s 514ms/step - loss: 1.8607 - accuracy: 0.4628 - val_loss: 2.1929 - val_accuracy: 0.3662\n",
      "Epoch 236/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.8435 - accuracy: 0.4517 - val_loss: 2.1602 - val_accuracy: 0.3944\n",
      "Epoch 237/250\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 1.8167 - accuracy: 0.4406 - val_loss: 2.1225 - val_accuracy: 0.3662\n",
      "Epoch 238/250\n",
      "4/7 [================>.............] - ETA: 1s - loss: 1.8041 - accuracy: 0.4375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DMCKEN~1\\AppData\\Local\\Temp/ipykernel_3776/2302428821.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                     validation_split=0.1)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 250\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(layers.Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=(300)))\n",
    "model.add(layers.Embedding(input_dim=text_vectorizer.vocabulary_size(), output_dim=(300)))\n",
    "#model.add(layers.SimpleRNN(200,return_sequences=True))\n",
    "model.add(layers.GRU(50))\n",
    "#model.add(layers.Dense(50))\n",
    "model.add(layers.Dense(23,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(skX, tf.constant(y_train),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9813544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine vectorizier and model \n",
    "\n",
    "model_for_inference = keras.Sequential([text_vectorizer, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70257616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.8932\n",
      "Test accuracy: 0.8931623697280884\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(vectorized2, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a2e983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=list(pd.DataFrame({\"q\":train_tags,\"b\":y_train.argmax(axis=-1)}).drop_duplicates(subset=['q','b']).sort_values('b')['q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b5d2a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "classed = np.argmax(model_for_inference.predict(X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4de5011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabs=[]\n",
    "for i in np.argmax(y_test,axis=1):\n",
    "    testlabs.append(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "975bff6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classroom',\n",
       " 'classroom',\n",
       " 'office specialist',\n",
       " 'science',\n",
       " 'science',\n",
       " 'bathroom',\n",
       " 'storage',\n",
       " 'mechanical',\n",
       " 'principal vice',\n",
       " 'classroom',\n",
       " 'science',\n",
       " 'office specialist',\n",
       " 'gym',\n",
       " 'bathroom',\n",
       " 'bathroom',\n",
       " 'bathroom',\n",
       " 'mechanical',\n",
       " 'classroom',\n",
       " 'locker shower',\n",
       " 'custodial',\n",
       " 'classroom',\n",
       " 'other',\n",
       " 'classroom',\n",
       " 'other',\n",
       " 'lab',\n",
       " 'locker shower',\n",
       " 'other',\n",
       " 'classroom',\n",
       " 'office specialist',\n",
       " 'classroom',\n",
       " 'storage',\n",
       " 'gym',\n",
       " 'office specialist',\n",
       " 'classroom',\n",
       " 'library sto',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'lab',\n",
       " 'mechanical',\n",
       " 'electrical',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'gym',\n",
       " 'office specialist',\n",
       " 'music vocal',\n",
       " 'storage',\n",
       " 'storage',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'other',\n",
       " 'bathroom',\n",
       " 'storage',\n",
       " 'classroom',\n",
       " 'shower',\n",
       " 'classroom',\n",
       " 'science',\n",
       " 'bathroom',\n",
       " 'mechanical',\n",
       " 'storage',\n",
       " 'other',\n",
       " 'science',\n",
       " 'science',\n",
       " 'kitchen district',\n",
       " 'lab',\n",
       " 'gym',\n",
       " 'classroom',\n",
       " 'storage',\n",
       " 'science',\n",
       " 'office specialist',\n",
       " 'lab',\n",
       " 'music vocal',\n",
       " 'classroom',\n",
       " 'lobby vest',\n",
       " 'kitchen district',\n",
       " 'science',\n",
       " 'classroom',\n",
       " 'storage',\n",
       " 'custodial',\n",
       " 'science',\n",
       " 'science',\n",
       " 'classroom',\n",
       " 'other',\n",
       " 'classroom',\n",
       " 'locker shower',\n",
       " 'storage',\n",
       " 'art exist',\n",
       " 'lab',\n",
       " 'mechanical',\n",
       " 'storage',\n",
       " 'office specialist',\n",
       " 'art exist',\n",
       " 'classroom',\n",
       " 'storage',\n",
       " 'lab',\n",
       " 'office specialist',\n",
       " 'office specialist',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'office specialist',\n",
       " 'classroom',\n",
       " 'art exist',\n",
       " 'bathroom',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'bathroom',\n",
       " 'lab',\n",
       " 'library sto',\n",
       " 'locker shower',\n",
       " 'gym',\n",
       " 'other',\n",
       " 'lab',\n",
       " 'storage',\n",
       " 'office specialist',\n",
       " 'storage',\n",
       " 'locker shower',\n",
       " 'science',\n",
       " 'locker shower',\n",
       " 'bathroom',\n",
       " 'conference large',\n",
       " 'art exist',\n",
       " 'office specialist',\n",
       " 'classroom',\n",
       " 'conference large',\n",
       " 'conference large',\n",
       " 'storage',\n",
       " 'office specialist',\n",
       " 'storage',\n",
       " 'storage',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'bathroom',\n",
       " 'storage',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'locker shower',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'science',\n",
       " 'a.v.',\n",
       " 'lobby vest',\n",
       " 'art exist',\n",
       " 'classroom',\n",
       " 'lounge leadership',\n",
       " 'classroom',\n",
       " 'storage',\n",
       " 'office specialist',\n",
       " 'locker shower',\n",
       " 'office specialist',\n",
       " 'art exist',\n",
       " 'gym',\n",
       " 'gym',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'principal vice',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'classroom',\n",
       " 'locker shower',\n",
       " 'storage',\n",
       " 'science',\n",
       " 'locker shower',\n",
       " 'office specialist',\n",
       " 'corridor',\n",
       " 'lab',\n",
       " 'locker shower',\n",
       " 'principal vice',\n",
       " 'corridor',\n",
       " 'storage',\n",
       " 'lab',\n",
       " 'lab',\n",
       " 'gym',\n",
       " 'classroom',\n",
       " 'a.v.',\n",
       " 'classroom',\n",
       " 'mechanical',\n",
       " 'lab',\n",
       " 'locker shower',\n",
       " 'lab',\n",
       " 'science',\n",
       " 'lab',\n",
       " 'mechanical',\n",
       " 'office specialist',\n",
       " 'lounge leadership',\n",
       " 'library sto',\n",
       " 'other',\n",
       " 'bathroom',\n",
       " 'storage',\n",
       " 'lab',\n",
       " 'mechanical',\n",
       " 'storage',\n",
       " 'storage',\n",
       " 'locker shower',\n",
       " 'music vocal',\n",
       " 'lobby vest',\n",
       " 'classroom',\n",
       " 'mechanical',\n",
       " 'classroom',\n",
       " 'storage',\n",
       " 'mechanical',\n",
       " 'lab',\n",
       " 'office specialist',\n",
       " 'classroom',\n",
       " 'science',\n",
       " 'lab',\n",
       " 'classroom',\n",
       " 'bathroom',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'bathroom',\n",
       " 'classroom',\n",
       " 'art exist',\n",
       " 'office specialist',\n",
       " 'locker shower',\n",
       " 'locker shower',\n",
       " 'lab',\n",
       " 'corridor',\n",
       " 'art exist',\n",
       " 'bathroom',\n",
       " 'corridor',\n",
       " 'conference large',\n",
       " 'corridor',\n",
       " 'lab',\n",
       " 'lab',\n",
       " 'other',\n",
       " 'music vocal',\n",
       " 'classroom',\n",
       " 'office specialist',\n",
       " 'art exist',\n",
       " 'lab',\n",
       " 'lab',\n",
       " 'classroom',\n",
       " 'locker shower',\n",
       " 'locker shower',\n",
       " 'locker shower',\n",
       " 'other',\n",
       " 'other',\n",
       " 'storage',\n",
       " 'lab',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'lounge leadership',\n",
       " 'storage',\n",
       " 'storage',\n",
       " 'classroom',\n",
       " 'bathroom',\n",
       " 'other',\n",
       " 'gym',\n",
       " 'office specialist',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'office specialist',\n",
       " 'storage',\n",
       " 'locker shower',\n",
       " 'library sto',\n",
       " 'art exist',\n",
       " 'art exist',\n",
       " 'classroom',\n",
       " 'storage',\n",
       " 'bathroom',\n",
       " 'office specialist',\n",
       " 'lab',\n",
       " 'storage',\n",
       " 'conference large',\n",
       " 'bathroom',\n",
       " 'science',\n",
       " 'lobby vest',\n",
       " 'bathroom',\n",
       " 'conference large',\n",
       " 'office specialist',\n",
       " 'lab',\n",
       " 'a.v.',\n",
       " 'shower',\n",
       " 'custodial',\n",
       " 'corridor',\n",
       " 'science',\n",
       " 'mechanical',\n",
       " 'classroom',\n",
       " 'office specialist',\n",
       " 'classroom',\n",
       " 'office specialist',\n",
       " 'gym',\n",
       " 'locker shower',\n",
       " 'classroom',\n",
       " 'locker shower',\n",
       " 'office specialist',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'office specialist',\n",
       " 'principal vice',\n",
       " 'bathroom',\n",
       " 'lab',\n",
       " 'lab',\n",
       " 'bathroom',\n",
       " 'corridor',\n",
       " 'lab',\n",
       " 'office specialist',\n",
       " 'lab',\n",
       " 'office specialist',\n",
       " 'conference large',\n",
       " 'storage',\n",
       " 'music vocal',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'conference large',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'custodial',\n",
       " 'classroom',\n",
       " 'science',\n",
       " 'locker shower',\n",
       " 'other',\n",
       " 'classroom',\n",
       " 'bathroom',\n",
       " 'mechanical',\n",
       " 'a.v.',\n",
       " 'science',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'conference large',\n",
       " 'conference large',\n",
       " 'storage',\n",
       " 'storage',\n",
       " 'bathroom',\n",
       " 'lab',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'bathroom',\n",
       " 'art exist',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'science',\n",
       " 'storage',\n",
       " 'classroom',\n",
       " 'storage',\n",
       " 'gym',\n",
       " 'gym',\n",
       " 'storage',\n",
       " 'storage',\n",
       " 'office specialist',\n",
       " 'storage',\n",
       " 'bathroom',\n",
       " 'lounge leadership',\n",
       " 'mechanical',\n",
       " 'storage',\n",
       " 'bathroom',\n",
       " 'locker shower',\n",
       " 'other',\n",
       " 'lab',\n",
       " 'science',\n",
       " 'bathroom',\n",
       " 'music vocal',\n",
       " 'bathroom',\n",
       " 'locker shower',\n",
       " 'classroom',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'principal vice',\n",
       " 'shower',\n",
       " 'gym',\n",
       " 'other',\n",
       " 'storage',\n",
       " 'bathroom',\n",
       " 'other',\n",
       " 'lab',\n",
       " 'lab',\n",
       " 'lab',\n",
       " 'other',\n",
       " 'library sto',\n",
       " 'office specialist',\n",
       " 'science',\n",
       " 'lobby vest',\n",
       " 'other',\n",
       " 'science',\n",
       " 'bathroom',\n",
       " 'classroom',\n",
       " 'office specialist',\n",
       " 'gym',\n",
       " 'locker shower',\n",
       " 'mechanical',\n",
       " 'storage',\n",
       " 'classroom',\n",
       " 'office specialist',\n",
       " 'office specialist',\n",
       " 'classroom',\n",
       " 'office specialist',\n",
       " 'lobby vest',\n",
       " 'principal vice',\n",
       " 'bathroom',\n",
       " 'storage',\n",
       " 'a.v.',\n",
       " 'lab',\n",
       " 'a.v.',\n",
       " 'lab',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'library sto',\n",
       " 'lab',\n",
       " 'locker shower',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'science',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'music vocal',\n",
       " 'kitchen district',\n",
       " 'corridor',\n",
       " 'storage',\n",
       " 'conference large',\n",
       " 'science',\n",
       " 'classroom',\n",
       " 'library sto',\n",
       " 'science',\n",
       " 'locker shower',\n",
       " 'storage',\n",
       " 'storage',\n",
       " 'music vocal',\n",
       " 'science',\n",
       " 'shower',\n",
       " 'electrical',\n",
       " 'classroom',\n",
       " 'office specialist',\n",
       " 'storage',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'classroom',\n",
       " 'lab',\n",
       " 'classroom',\n",
       " 'library sto',\n",
       " 'locker shower',\n",
       " 'classroom',\n",
       " 'bathroom',\n",
       " 'office specialist',\n",
       " 'lab',\n",
       " 'bathroom',\n",
       " 'storage',\n",
       " 'classroom',\n",
       " 'locker shower',\n",
       " 'office specialist',\n",
       " 'storage',\n",
       " 'storage',\n",
       " 'bathroom',\n",
       " 'art exist',\n",
       " 'library sto',\n",
       " 'lab',\n",
       " 'corridor',\n",
       " 'classroom',\n",
       " 'classroom',\n",
       " 'science',\n",
       " 'locker shower',\n",
       " 'bathroom',\n",
       " 'lab',\n",
       " 'corridor',\n",
       " 'mechanical',\n",
       " 'lab',\n",
       " 'a.v.',\n",
       " 'custodial',\n",
       " 'storage',\n",
       " 'lab',\n",
       " 'other',\n",
       " 'office specialist',\n",
       " 'corridor',\n",
       " 'locker shower',\n",
       " 'lobby vest',\n",
       " 'locker shower']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs=[]\n",
    "for i in classed:\n",
    "    labs.append(classes[i])\n",
    "labs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dbda2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({'Guess':labs,\n",
    "              'Win':(np.array(labs)==np.array(testlabs))*1}).assign(dummy=1).groupby('Guess').agg('sum').reset_index().\\\n",
    "    assign(WinRate=lambda x : x.Win/x.dummy)['WinRate'].hist()\n",
    "print(pd.DataFrame({'Guess':labs,\n",
    "              'Win':(np.array(labs)==np.array(testlabs))*1}).assign(dummy=1).groupby('Guess').agg('sum').reset_index().\\\n",
    "    assign(WinRate=lambda x : x.Win/x.dummy)['WinRate'].median())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
